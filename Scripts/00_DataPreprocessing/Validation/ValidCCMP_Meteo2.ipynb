{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import numpy  as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import AutoMinorLocator, StrMethodFormatter\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from gsw import p_from_z\n",
    "from gsw import pot_rho_t_exact as prho\n",
    "\n",
    "import seaborn as sns\n",
    "# sns.reset_defaults()\n",
    "sns.set_theme(style='darkgrid')\n",
    "# sns.set_context('talk')\n",
    "\n",
    "import datetime\n",
    "\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy import interpolate, ndimage, stats\n",
    "from PIL import Image\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "from datetime import datetime, date\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append(os.path.abspath(\"D:/00_Masters/00_Work/\"))\n",
    "from Utils.inertP import *\n",
    "from Utils.veldire2uv import *\n",
    "from Utils.HistDir import *\n",
    "from Utils.uv2veldire import *\n",
    "from Utils.rmse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2845af",
   "metadata": {},
   "source": [
    "##### Informacoes adicionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coast_angle_Corr = [-15,0,20,40,40,45] # correção para estação de salvador baseado na literatura, nao no grau calculado \n",
    "# names = ['SBNT','SBJP','SBRF','SBMO','SBAR','SBSV']   \n",
    "# Metar_describ = pd.DataFrame({'label':['SBNT','SBJP','SBRF','SBMO','SBAR','SBSV'],\n",
    "#                       'Latitude':[-5.91,-7.15,-8.13,-9.51,-10.98,-12.91],\n",
    "#                       'Longitude': [-35.25,-34.97,-34.92,-35.79,-37.07,-38.33]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2845af",
   "metadata": {},
   "source": [
    "##### Dataset do ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsmerged = xr.open_dataset('D:/00_Masters/01_Dados/ERA5/ERA5.nc')\n",
    "dsmerged = dsmerged.sel(time=slice('2014-11-25', '2019-12-31')) #Slice do tempo para validação do dados\n",
    "\n",
    "# era_SBNT = dsmerged.sel(latitude=-5.8, longitude=-35.1, method='nearest') # 2º point-5.8 -34.85\n",
    "# uE_SBNT = era_SBNT['u10']\n",
    "# vN_SBNT = era_SBNT['v10']\n",
    "\n",
    "# era_SBJP = dsmerged.sel(latitude=-7.05, longitude=-34.6, method='nearest') # 2º point-7.05 -34.35\n",
    "# uE_SBJP = era_SBJP['u10']\n",
    "# vN_SBJP = era_SBJP['v10']\n",
    "\n",
    "# era_SBRF = dsmerged.sel(latitude=-8.05, longitude=-34.6, method='nearest') # 2º point-8.05 -34.35\n",
    "# uE_SBRF = era_SBRF['u10']\n",
    "# vN_SBRF = era_SBRF['v10']\n",
    "\n",
    "# era_SBMO = dsmerged.sel(latitude=-9.55, longitude=-35.35, method='nearest') # 2º point-9.55 -35.1\n",
    "# uE_SBMO = era_SBMO['u10']\n",
    "# vN_SBMO = era_SBMO['v10']\n",
    "\n",
    "# era_SBAR = dsmerged.sel(latitude=-11.05, longitude=-36.85, method='nearest') # 2º point -11.05 -36.6\n",
    "# uE_SBAR = era_SBAR['u10']\n",
    "# vN_SBAR = era_SBAR['v10']\n",
    "\n",
    "era_SBSV = dsmerged.sel(latitude=-13.05, longitude=-38.35, method='nearest') # 2º point -12.8/-13.05 -37.85/-38.1\n",
    "uE_SBSV = era_SBSV['u10']\n",
    "vN_SBSV = era_SBSV['v10']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2845af",
   "metadata": {},
   "source": [
    "##### Dataset do CCMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Preparar loop para leitura de diversos pontos\n",
    "        tratamento dos dados\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('d:/00_Masters/01_Dados/CCMP_PF_1998_2022.mat')\n",
    "\n",
    "# mat['CCMP_vE_vN_oceanografico']\n",
    "# Correção em relaçao a costa feita anteriormente (40º de correcao!) utilizar CCMP_u_v\n",
    "# para provar uE, vN = map(list, zip(*mat['CCMP_u_v'])); velC, dirC = uv2veldire(-uE,-vN)\n",
    "\n",
    "# time = pd.DataFrame(mat['time_CCMP_g'],columns=['year','month','day','hour','min','sec'])\n",
    "time = pd.date_range(start='1988-02-28 00:00:00',end='2022-04-26 18:00:00',freq='3h')\n",
    "u, v = map(list, zip(*mat['CCMP_u_v']))\n",
    "u = pd.DataFrame(u,columns=['u']).set_index(time)\n",
    "v = pd.DataFrame(v,columns=['v']).set_index(time)\n",
    "velC, dirC = uv2veldire(-u['u'],-v['v'])\n",
    "velC = pd.DataFrame(velC,columns=['speed']).set_index(time)\n",
    "dirC = pd.DataFrame(dirC,columns=['direction']).set_index(time)\n",
    "\n",
    "CCMP = pd.concat([velC, dirC ,u, v], axis=1, join=\"inner\")\n",
    "CCMP = CCMP['2014-11-25': '2019-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2845af",
   "metadata": {},
   "source": [
    "##### Dataset do METAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metar_describ = pd.DataFrame({'label':['SBSV'],\n",
    "                      'Latitude':[-12.91],\n",
    "                      'Longitude': [-38.33]})\n",
    "\n",
    "\n",
    "i = [0,1,2,3,4,5]\n",
    "df_list =[]\n",
    "\n",
    "for n in range(len(names)):\n",
    "    df = pd.read_csv(\"D:/00_Masters/01_Dados/METAR/\"+ names[n] +\".csv\",sep=',',\n",
    "    index_col='times', parse_dates=True)\n",
    "    df = df['2014-11-25':'2019-12-31'] # Slice do tempo para validação dos dados\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculo do período inericial e filtragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = [-13.05]\n",
    "Coast_angle_Corr = [45]\n",
    "names = ['SBSV']   \n",
    "\n",
    "P = []\n",
    "for i in lat:\n",
    "    P.append(inertP(lat=i)) #MEtar_describ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era = {}\n",
    "\n",
    "for n,fi,c in zip(names,P,Coast_angle_Corr):\n",
    "    varU = eval('uE_{}'.format(n)).to_dataframe()\n",
    "    varU = varU.rolling(str((fi*-1//24)+1)+'D',center=True).mean()\n",
    "    varU = varU.resample('1D').mean()\n",
    "\n",
    "    varN = eval('vN_{}'.format(n)).to_dataframe()\n",
    "    varN = varN.rolling(str((fi*-1//24)+1)+'D',center=True).mean()\n",
    "    varN = varN.resample('1D').mean()\n",
    "\n",
    "    erat = varU\n",
    "    erat['v10'] = varN['v10']\n",
    "    erat['speed'], erat['direction'] = uv2veldire(erat['u10'],erat['v10'],corr_val=c)#\n",
    "    erat['u'], erat['v'] = veldire2uv(erat['speed'], erat['direction']) #Replica a coluna para caso haja correção em relação a costa e ajusta nome da coluna\n",
    "    \n",
    "    #transformando o vento para convenção oceanográfica (Vento direcionado para onde está indo - semelhante a CORRENTE)\n",
    "    erat['direction'] -= 180 \n",
    "    erat['direction'][erat['direction']<0] += 360\n",
    "\n",
    "    era['era_{}'.format(n)] = erat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            CCMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmp = {}\n",
    "\n",
    "for i,n,fi,c in zip(range(0,len(names)),names,P,Coast_angle_Corr):\n",
    "    ccmpTemp = CCMP.rolling(str((fi*-1//24)+1)+'D',center=True).mean()\n",
    "    ccmpTemp = ccmpTemp.resample('1D').mean()\n",
    "\n",
    "    ccmp['ccmp_{}'.format(n)] = ccmpTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            METAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = {}\n",
    "\n",
    "for i,n,fi,c in zip(range(0,len(names)),names,P,Coast_angle_Corr):\n",
    "    ban = df_list[i].rolling(str((fi*-1//24)+1)+'D',center=True).mean()\n",
    "    ban = ban.resample('1D').mean()\n",
    "    ban['direction'] = ban['direction'] - c\n",
    "    ban['u'],ban['v'] = veldire2uv(ban['speed'],ban['direction'])\n",
    "    ban = ban.interpolate(method='linear')\n",
    "    ban['direction'] -=180\n",
    "    ban['direction'][ban['direction']<0] += 360\n",
    "\n",
    "    met['{}'.format(n)] = ban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIles e Figs - Estatísticas Básicas e Correlação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            Estatísticas e Correlaçoes para periodo total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['speed','direction','u','v']\n",
    "nam = ['ERA5', 'CCMP']\n",
    "path_output = 'D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/'\n",
    "\n",
    "\n",
    "for n in names:\n",
    "    schema = [era['era_{}'.format(n)], ccmp['ccmp_{}'.format(n)]]\n",
    "    f1 = open(os.path.join(path_output, './{}/'.format(n),'./Correlacoes_STATs/CCMP_Stats_WND_{}.txt'.format(n)) , 'w')\n",
    "    print('\\n\\t',n,file=f1)\n",
    "\n",
    "    for v in vars:\n",
    "        for i in range(0,len(schema)):\n",
    "            print('\\n',nam[i],' - Variable: ',v,file=f1)\n",
    "            print(stats.describe(schema[i][v],nan_policy='omit'), ('std= '+str(np.std(schema[i][v]))),file=f1)\n",
    "    f1.close()\n",
    "\n",
    "    f2 = open(os.path.join(path_output,  './{}/'.format(n),'./Correlacoes_STATs/CCMP_R2_{}.txt'.format(n)) , 'w')\n",
    "    R = []\n",
    "    RMSE = []\n",
    "    for v in vars:\n",
    "        for i in range(0,len(schema)-1):\n",
    "            res = stats.pearsonr(x=schema[i+1][v],y=schema[0][v])\n",
    "            err = rmse(schema[i+1][v],schema[0][v])\n",
    "            print('\\n',' - Variable: ',v,file=f2)\n",
    "            print('Pearson Corr. -', nam[i+1], nam[0],file=f2)\n",
    "            print(res,file=f2)\n",
    "            print('Root Mean Square Error RMSE -', nam[i+1], nam[0],file=f2)\n",
    "            print(err,file=f2)\n",
    "\n",
    "            R.append(np.round(res[0],2))\n",
    "            RMSE.append(np.round(err,2))\n",
    "    f2.close()\n",
    "\n",
    "    ''' \n",
    "    FIGURA COM SeaBorn\n",
    "\n",
    "    '''\n",
    "    for ind,v in enumerate(vars):\n",
    "        fig, [ax1,ax2] = plt.subplots(nrows=1, ncols=2, gridspec_kw={'width_ratios':[2,2], 'height_ratios':[1]})\n",
    "        cmap = sns.color_palette(as_cmap=True)\n",
    "\n",
    "        with sns.axes_style(\"darkgrid\"):\n",
    "            for i in range(0,len(schema)):\n",
    "                ax1 = sns.kdeplot(data=schema[i][v], x = schema[i][v], fill=True, alpha=.2, linewidth=2, bw=0.2, ax=ax1)\n",
    "\n",
    "        with sns.axes_style(\"darkgrid\"):\n",
    "            for i in range(0,len(schema)-1):\n",
    "                ax2 = sns.regplot(x=schema[i+1][v], y=schema[0][v], color=cmap[i+1], fit_reg = False, ax=ax2)\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "        fig.suptitle('{}'.format(n)+' - '+v.format().capitalize(),fontsize=14,y=.95)\n",
    "\n",
    "        if str(v) == 'speed':\n",
    "            unit = \"[m.s$^{-1}$]\"\n",
    "            ax1.set_xticks(np.arange(0,12,2.5))\n",
    "            ax2.set_xticks(np.arange(0,12,2.5))\n",
    "            ax2.set_yticks(np.arange(0,12,2.5))\n",
    "            ax1.set_ylim(0,.7)\n",
    "        elif str(v) == 'direction':\n",
    "            unit = \"[°]\"\n",
    "            ax1.set_xticks(np.arange(0,360,90))\n",
    "            ax2.set_xticks(np.arange(0,360,90))\n",
    "            ax2.set_yticks(np.arange(0,360,90))\n",
    "            ax1.set_ylim(0,0.04)\n",
    "        else:\n",
    "            unit = \"\"\n",
    "            ax1.set_xticks(np.arange(-8,10,2))\n",
    "            ax2.set_xticks(np.arange(-8,10,2))\n",
    "            ax2.set_yticks(np.arange(-8,10,2))\n",
    "            ax1.set_ylim(0,.56)\n",
    "\n",
    "        ax1.set_xlabel(unit)\n",
    "        ax2.set_xlabel(nam[1] + ' ' + unit)\n",
    "        ax2.set_ylabel(nam[0] + ' ' + unit)\n",
    "        \n",
    "        ax1.legend(nam,fontsize=12, bbox_to_anchor = (-.2,-.18),loc='upper left', ncol=3)\n",
    "\n",
    "        # ax2.annotate('Pearson. Coef.:', fontsize=6.5,color='k',xy=(.6,.15),xycoords='axes fraction')\n",
    "        ax2.annotate(\"$r^2$ = \" + str(R[ind]), fontsize=6.5,color=cmap[1],\n",
    "                    xy=(.6, .1), xycoords='axes fraction',fontweight=\"bold\")\n",
    "        ax2.annotate(\"RMSE = \" + str(RMSE[ind]), fontsize=6.5,color=cmap[1],\n",
    "                    xy=(.6, .065), xycoords='axes fraction',fontweight=\"bold\")\n",
    "        \n",
    "\n",
    "        plt.savefig('D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/{}/Correlacoes_STATs/CCMP_{}_{}.png'.format(n,n,v), format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCMP X METAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['speed','direction','u','v']\n",
    "nam = ['Metar','CCMP']\n",
    "path_output = 'D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/'\n",
    "\n",
    "\n",
    "for n in names:\n",
    "    schema = [met[n], ccmp['ccmp_{}'.format(n)],]\n",
    "    f1 = open(os.path.join(path_output, './{}/'.format(n),'./Correlacoes_STATs/CCMP-Met_Stats_WND_{}.txt'.format(n)) , 'w')\n",
    "    print('\\n\\t',n,file=f1)\n",
    "\n",
    "    for v in vars:\n",
    "        for i in range(0,len(schema)):\n",
    "            print('\\n',nam[i],' - Variable: ',v,file=f1)\n",
    "            print(stats.describe(schema[i][v],nan_policy='omit'), ('std= '+str(np.std(schema[i][v]))),file=f1)\n",
    "    f1.close()\n",
    "\n",
    "    f2 = open(os.path.join(path_output,  './{}/'.format(n),'./Correlacoes_STATs/CCMP-Met_R2_{}.txt'.format(n)) , 'w')\n",
    "    R = []\n",
    "    RMSE = []\n",
    "    for v in vars:\n",
    "        for i in range(0,len(schema)-1):\n",
    "            res = stats.pearsonr(x=schema[i+1][v],y=schema[0][v])\n",
    "            err = rmse(schema[i+1][v],schema[0][v])\n",
    "            print('\\n',' - Variable: ',v,file=f2)\n",
    "            print('Pearson Corr. -', nam[i+1], nam[0],file=f2)\n",
    "            print(res,file=f2)\n",
    "            print('Root Mean Square Error RMSE -', nam[i+1], nam[0],file=f2)\n",
    "            print(err,file=f2)\n",
    "\n",
    "            R.append(np.round(res[0],2))\n",
    "            RMSE.append(np.round(err,2))\n",
    "    f2.close()\n",
    "\n",
    "    ''' \n",
    "    FIGURA COM SeaBorn\n",
    "\n",
    "    '''\n",
    "    for ind,v in enumerate(vars):\n",
    "        fig, [ax1,ax2] = plt.subplots(nrows=1, ncols=2, gridspec_kw={'width_ratios':[2,2], 'height_ratios':[1]})\n",
    "        cmap = sns.color_palette(as_cmap=True)\n",
    "\n",
    "        with sns.axes_style(\"darkgrid\"):\n",
    "            for i,c in zip(range(0,len(schema)),[3,1]):\n",
    "                ax1 = sns.kdeplot(data=schema[i][v], x = schema[i][v], color=cmap[c], fill=True, alpha=.2, linewidth=2, bw=0.2, ax=ax1)\n",
    "\n",
    "        with sns.axes_style(\"darkgrid\"):\n",
    "            for i in range(0,len(schema)-1):\n",
    "                ax2 = sns.regplot(x=schema[i+1][v], y=schema[0][v], color=cmap[i+1], fit_reg = False, ax=ax2)\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "        fig.suptitle('{}'.format(n)+' - '+v.format().capitalize(),fontsize=14,y=.95)\n",
    "\n",
    "        if str(v) == 'speed':\n",
    "            unit = \"[m.s$^{-1}$]\"\n",
    "            ax1.set_xticks(np.arange(0,12,2.5))\n",
    "            ax2.set_xticks(np.arange(0,12,2.5))\n",
    "            ax2.set_yticks(np.arange(0,12,2.5))\n",
    "            ax1.set_ylim(0,.7)\n",
    "        elif str(v) == 'direction':\n",
    "            unit = \"[°]\"\n",
    "            ax1.set_xticks(np.arange(0,360,90))\n",
    "            ax2.set_xticks(np.arange(0,360,90))\n",
    "            ax2.set_yticks(np.arange(0,360,90))\n",
    "            ax1.set_ylim(0,0.04)\n",
    "        else:\n",
    "            unit = \"\"\n",
    "            ax1.set_xticks(np.arange(-8,10,2))\n",
    "            ax2.set_xticks(np.arange(-8,10,2))\n",
    "            ax2.set_yticks(np.arange(-8,10,2))\n",
    "            ax1.set_ylim(0,.56)\n",
    "\n",
    "        ax1.set_xlabel(unit)\n",
    "        ax2.set_xlabel(nam[1] + ' ' + unit)\n",
    "        ax2.set_ylabel(nam[0] + ' ' + unit)\n",
    "        \n",
    "        ax1.legend(nam,fontsize=12, bbox_to_anchor = (-.2,-.18),loc='upper left', ncol=3)\n",
    "\n",
    "        # ax2.annotate('Pearson. Coef.:', fontsize=6.5,color='k',xy=(.6,.15),xycoords='axes fraction')\n",
    "        ax2.annotate(\"$r^2$ = \" + str(R[ind]), fontsize=6.5,color=cmap[1],\n",
    "                    xy=(.6, .1), xycoords='axes fraction',fontweight=\"bold\")\n",
    "        ax2.annotate(\"RMSE = \" + str(RMSE[ind]), fontsize=6.5,color=cmap[1],\n",
    "                    xy=(.6, .065), xycoords='axes fraction',fontweight=\"bold\")\n",
    "        \n",
    "\n",
    "        plt.savefig('D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/{}/Correlacoes_STATs/CCMP-Met_{}_{}.png'.format(n,n,v), format='png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Season = [[1,2,3],[4,5,6],[4,5,6],[10,11,12]] #[[12,1,2],[3,4,5],[6,7,8],[9,10,11]] \n",
    "Season_names = ['SUMMER','AUTUMN','WINTER','SPRING']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            SEASONAL Estatísticas e Correlaçoes\n",
    "                Season = [[1,2,3],[4,5,6],[4,5,6],[10,11,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in names:\n",
    "    for s,sn in zip(Season,Season_names):\n",
    "        ccmp_season = ccmp['ccmp_{}'.format(n)]\n",
    "        ccmp_season = ccmp_season[ccmp_season.index.month.isin(s)]\n",
    "        era_season = era['era_{}'.format(n)]\n",
    "        era_season = era_season[era_season.index.month.isin(s)]\n",
    "        \n",
    "        schema = [ccmp_season, era_season]\n",
    "\n",
    "        f1 = open(os.path.join(path_output, './{}/'.format(n),'./Correlacoes_STATs/CCMP_Stats_WND_{}_{}.txt'.format(n,sn)) , 'w')\n",
    "        print('\\n\\t',n,sn,file=f1)\n",
    "\n",
    "        for v in vars:\n",
    "            for i in range(0,len(schema)):\n",
    "                print('\\n',nam[i],' - Variable: ',v,file=f1)\n",
    "                print(stats.describe(schema[i][v],nan_policy='omit'), ('std= '+str(np.std(schema[i][v]))),file=f1)\n",
    "        f1.close()\n",
    "\n",
    "        f2 = open(os.path.join(path_output, './{}/'.format(n),'./Correlacoes_STATs/CCMP_R2_{}_{}.txt'.format(n,sn)) , 'w')\n",
    "        R = []\n",
    "        RMSE = []\n",
    "        for v in vars:\n",
    "            for i in range(0,len(schema)-1):\n",
    "                res = stats.pearsonr(x=schema[i+1][v],y=schema[0][v])\n",
    "                err = rmse(schema[i+1][v],schema[0][v])\n",
    "                print('\\n',' - Variable: ',v,file=f2)\n",
    "                print('\\nPearson Corr. -', nam[i+1], nam[0],file=f2)\n",
    "                print(res,file=f2)\n",
    "\n",
    "                R.append(np.round(res[0],5))\n",
    "                RMSE.append(np.round(err,3))                \n",
    "        f2.close()\n",
    "\n",
    "        ''' \n",
    "        FIGURA COM SeaBorn\n",
    "\n",
    "        '''\n",
    "        for v in vars:\n",
    "            fig, [ax1,ax2] = plt.subplots(nrows=1, ncols=2, gridspec_kw={'width_ratios':[2,2], 'height_ratios':[1]})\n",
    "            cmap = sns.color_palette(as_cmap=True)\n",
    "\n",
    "            with sns.axes_style(\"darkgrid\"):\n",
    "                for i in range(0,len(schema)):\n",
    "                    ax1 = sns.kdeplot(data=schema[i][v], x = schema[i][v], fill=True, alpha=.2, linewidth=2, bw=0.2, ax=ax1)\n",
    "\n",
    "            with sns.axes_style(\"darkgrid\"):\n",
    "                for i in range(0,len(schema)-1):\n",
    "                    ax2 = sns.regplot(x=schema[i+1][v], y=schema[0][v], color=cmap[i+1], fit_reg = False, ax=ax2)\n",
    "\n",
    "            fig.subplots_adjust(wspace=0.4)\n",
    "            fig.suptitle('{}-{}'.format(n,sn)+' - '+v,fontsize=14,y=.95)\n",
    "\n",
    "            if str(v) == 'speed':\n",
    "                unit = \"[m.s$^{-1}$]\"\n",
    "                ax1.set_xticks(np.arange(0,12,2.5))\n",
    "                ax2.set_xticks(np.arange(0,12,2.5))\n",
    "                ax2.set_yticks(np.arange(0,12,2.5))\n",
    "                ax1.set_ylim(0,1)\n",
    "            elif str(v) == 'direction':\n",
    "                unit = \"[°]\"\n",
    "                ax1.set_xticks(np.arange(0,360,90))\n",
    "                ax2.set_xticks(np.arange(0,360,90))\n",
    "                ax2.set_yticks(np.arange(0,360,90))\n",
    "                ax1.set_ylim(0,0.08)\n",
    "            else:\n",
    "                unit = \"\"\n",
    "                ax1.set_xticks(np.arange(-8,10,2))\n",
    "                ax2.set_xticks(np.arange(-8,10,2))\n",
    "                ax2.set_yticks(np.arange(-8,10,2))\n",
    "                ax1.set_ylim(0,1)\n",
    "\n",
    "            ax1.set_xlabel(unit)\n",
    "            ax2.set_xlabel('ERA5 ' + unit)\n",
    "            ax2.set_ylabel('CCMP ' + unit)\n",
    "            \n",
    "            ax1.legend(nam,fontsize=12, bbox_to_anchor = (-.2,-.18),loc='upper left', ncol=3)\n",
    "\n",
    "            ax2.annotate('Pearson. Coef.:', fontsize=6.5,color='k',xy=(.6,.15),xycoords='axes fraction')\n",
    "            ax2.annotate(\"$r^2$ = \" + str(R[ind]), fontsize=6.5,color=cmap[1],\n",
    "                        xy=(.6, .1), xycoords='axes fraction',fontweight=\"bold\")\n",
    "            ax2.annotate(\"RMSE = \" + str(RMSE[ind]), fontsize=6.5,color=cmap[1],\n",
    "                        xy=(.6, .065), xycoords='axes fraction',fontweight=\"bold\")\n",
    "\n",
    "            plt.savefig('D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/{}/Correlacoes_STATs/CCMP_{}_{}_{}.png'.format(n,n,v,sn), format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serie Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['speed','direction','u','v']\n",
    "nam = ['CCMP']\n",
    "path_output = 'D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/'\n",
    "\n",
    "for n in names:\n",
    "    schema = [ccmp['ccmp_{}'.format(n)],]\n",
    "\n",
    "    for v in vars:\n",
    "        fig, ax1 = plt.subplots(nrows=1, ncols=1, gridspec_kw={'width_ratios':[2], 'height_ratios':[1]})\n",
    "        cmap = sns.color_palette(as_cmap=True)\n",
    "        fig.suptitle('{}'.format(n).upper(),fontsize=14,y=.95)\n",
    "\n",
    "        with sns.axes_style(\"darkgrid\"):\n",
    "            for i in range(0,len(schema)):\n",
    "                ax1 = sns.lineplot(x=schema[i][v].index,y=schema[i][v],ax=ax1,color=cmap[1])\n",
    "\n",
    "        ax1.autoscale(enable=True, axis='x', tight=True)\n",
    "        ax1.legend(nam,fontsize=12, bbox_to_anchor = (0.35,-.14),loc='upper left', ncol=3)\n",
    "        ax1.set_xlabel('Year')\n",
    "        if str(v) == 'speed':\n",
    "                    unit = \"[m.s$^{-1}$]\"\n",
    "        elif str(v) == 'direction':\n",
    "                    unit = \"[°]\"\n",
    "        else:\n",
    "            unit = \"\"\n",
    "        ax1.set_ylabel('{}'.format(v).capitalize() + ' ' +unit)\n",
    "\n",
    "        plt.savefig('D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/{}/Serie_Temporal/CCMP_Serie_{}_{}.png'.format(n,n,v), format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HistDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refazendo dataset sem a correção para convenção oceanográfica do vento\n",
    "pois a rotina HistDir já faz automaticamente essa conversão;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era = {}\n",
    "\n",
    "for n,fi,c in zip(names,P,Coast_angle_Corr):\n",
    "    varU = eval('uE_{}'.format(n)).to_dataframe()\n",
    "    varU = varU.rolling(str((fi*-1//24)+1)+'D',center=True).mean()\n",
    "    varU = varU.resample('1D').mean()\n",
    "\n",
    "    varN = eval('vN_{}'.format(n)).to_dataframe()\n",
    "    varN = varN.rolling(str((fi*-1//24)+1)+'D',center=True).mean()\n",
    "    varN = varN.resample('1D').mean()\n",
    "\n",
    "    erat = varU\n",
    "    erat['v10'] = varN['v10']\n",
    "    erat['speed'], erat['direction'] = uv2veldire(erat['u10'],erat['v10'],corr_val=c)#\n",
    "    erat['u'], erat['v'] = veldire2uv(erat['speed'], erat['direction']) #Replica a coluna para caso haja correção em relação a costa e ajusta nome da coluna\n",
    "    \n",
    "    erat['direction'][erat['direction']<0] += 360\n",
    "\n",
    "    era['era_{}'.format(n)] = erat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            CCMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                     -- CCMP está corrigido para convenção oceanográfica, ou seja, precisamos criar o vetor inverso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmp = {}\n",
    "\n",
    "for i,n,fi,c in zip(range(0,len(names)),names,P,Coast_angle_Corr):\n",
    "    ccmpTemp = CCMP.rolling(str((fi*-1//24)+1)+'D',center=True).mean()\n",
    "    ccmpTemp = ccmpTemp.resample('1D').mean()\n",
    "\n",
    "    ccmpTemp['direction'] -= 180 \n",
    "    ccmpTemp['direction'][ccmpTemp['direction']<0] += 360\n",
    "\n",
    "    ccmp['ccmp_{}'.format(n)] = ccmpTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  4.  6.  8. 10.]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "vars = ['speed','direction']\n",
    "nam = ['CCMP']\n",
    "for n in names:\n",
    "    schema = [ccmp['ccmp_{}'.format(n)]]\n",
    "\n",
    "    for i in range(0,len(schema)):\n",
    "        outputname = 'D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/{}/HistDir/'.format(n)+str(nam[i])+'_'+str(n)\n",
    "        vel = schema[i]['speed']\n",
    "        dire = schema[i]['direction']\n",
    "        \n",
    "        HistDir(P=vel,D=dire,Pmax=10,MaxProb=80,\n",
    "                arqname=outputname,par='wind',interpolado=False, conv_oc=True)\n",
    "\n",
    "        for s,sn in zip(Season,Season_names):\n",
    "            \n",
    "            schema_S = schema[i]\n",
    "            schema_S = schema_S[schema_S.index.month.isin(s)]\n",
    "\n",
    "            outputname = 'D:/00_Masters/02_Resultados_Parciais/Validacao_Meteo/{}/HistDir/'.format(n)+str(n)+'_'+str(nam[i])+'_'+'_'+sn\n",
    "        \n",
    "            HistDir(P=schema_S['speed'],D=schema_S['direction'],Pmax=10,MaxProb=80,\n",
    "                    arqname=outputname,\n",
    "                    par='vento',interpolado=False, conv_oc=True)\n",
    "\n",
    "            print(str(n)+'_'+str(nam[i])+'_'+'_'+sn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
