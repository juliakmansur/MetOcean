{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from eofs.xarray import Eof\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import geopandas as gpd\n",
    "import rioxarray as rio\n",
    "from shapely.geometry import mapping, Polygon\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "rcParams['font.family'] = 'monospace'\n",
    "rcParams['font.sans-serif'] = ['Lucida Console']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_max(x, y, ax=None):\n",
    "    ymax = np.argsort(y)[-3:][::-1]\n",
    "    xmax = x[ymax]\n",
    "    for i in np.arange(0,3):\n",
    "        text = f\"x={xmax[i]:.1f}, y={y[ymax[i]]:.1e}\"\n",
    "        if not ax:\n",
    "            ax=plt.gca()\n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.3\", fc=\"w\", ec=\"darkred\", lw=0.72)\n",
    "        # arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=60,rad=5\")\n",
    "        kw = dict(xycoords='data',textcoords=\"axes fraction\",\n",
    "                bbox=bbox_props, ha=\"right\", va=\"top\")#arrowprops=arrowprops, \n",
    "        ax.annotate(text, xy=(xmax[i], y[ymax[i]]),  xytext=(0.94, 0.95-i/4), **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = 'd:/00_Masters/01_Dados/Shapes/brasil_UF.shp'\n",
    "\n",
    "extent = [-39.1,-33, -14.3,-4.3] # lonmin lonmax latmin latmax\n",
    "proj = ccrs.PlateCarree()\n",
    "\n",
    "shp_tomask = 'd:/00_Masters/01_Dados/Shapes/Buffer1GRAU_paraCORTE.shp'\n",
    "geodf = gpd.read_file(shp_tomask)\n",
    "geodf.set_crs(\"epsg:4326\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glorys Dataset -  First Time Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a list of all .nc files available in different folders\n",
    "filenames = glob.glob(\"d:/00_Masters/01_Dados/Mercator/*.nc\")\n",
    "dsmerged = xr.open_mfdataset(filenames)\n",
    "\n",
    "# # Corrige erro de datas duplicadas pelo mfdataset\n",
    "_, index = np.unique(dsmerged['time'], return_index=True)\n",
    "dsmerged = dsmerged.isel(time=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             Defining DEPTHS of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth_0 = dsmerged.sel(depth=0,method='nearest')\n",
    "temp_0 = Depth_0['thetao']\n",
    "clim_0 = temp_0.mean('time')#,skipna=True)\n",
    "\n",
    "Depth_30 = dsmerged.sel(depth=30,method='nearest')\n",
    "temp_30 = Depth_30['thetao']\n",
    "clim_30 = temp_30.mean('time')#,skipna=True)\n",
    "\n",
    "depths = [0,30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### REMOVING SEASONAL CICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Means_0 = temp_0.groupby(\"time.dayofyear\").mean()\n",
    "NoSeason_0 = temp_0.groupby(\"time.dayofyear\") - Means_0\n",
    "NoSeason_0 = NoSeason_0.to_dataframe()\n",
    "NoSeason_0 = NoSeason_0['thetao'].to_xarray()\n",
    "\n",
    "Means_30 = temp_30.groupby(\"time.dayofyear\").mean()\n",
    "NoSeason_30 = temp_30.groupby(\"time.dayofyear\") - Means_30\n",
    "NoSeason_30 = NoSeason_30.to_dataframe()\n",
    "NoSeason_30 = NoSeason_30['thetao'].to_xarray()\n",
    "\n",
    "ds_list = [NoSeason_0, NoSeason_30]\n",
    "ds_strings = ['0.49m','29.44m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             Exporting data to NC for better perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoSeason_0.to_netcdf('d:/00_Masters/01_Dados/NoSeason_0.nc')\n",
    "NoSeason_30.to_netcdf('d:/00_Masters/01_Dados/NoSeason_30.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing data from new NC for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoSeason_0 = xr.open_dataset('d:/00_Masters/01_Dados/NoSeason_0.nc')\n",
    "NoSeason_30 = xr.open_dataset('d:/00_Masters/01_Dados/NoSeason_30.nc')\n",
    "\n",
    "depths = [0,30]\n",
    "ds_list = [NoSeason_0['thetao'], NoSeason_30['thetao']]\n",
    "ds_strings = ['0.49m','29.44m']\n",
    "\n",
    "# # Adiciona referencia geospacial para corte\n",
    "for ds,i in zip(ds_list,range(0,len(depths))):\n",
    "    ds.rio.set_spatial_dims(\"longitude\",\"latitude\",inplace=True)\n",
    "    ds.rio.write_crs(\"epsg:4326\",inplace=True)\n",
    "\n",
    "    ds_list[i] = ds_list[i].rio.clip(geodf.geometry.apply(mapping), geodf.crs, drop=False, invert=False)     # clips everything - all nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute and plot the leading EOF of sea surface temperature (SST) in the\n",
    "west Atlantic.\n",
    "\n",
    "This routine uses the metadata-retaining xarray interface.\n",
    "\n",
    "Additional requirements for this example:\n",
    "    * xarray (http://xarray.pydata.org)\n",
    "    * matplotlib (http://matplotlib.org/)\n",
    "    * cartopy (http://scitools.org.uk/cartopy/)\n",
    "\"\"\"\n",
    "\n",
    "percent = {}\n",
    "n = 5 # set number of EOFs and PCs to calculate\n",
    "period = 1 #24*60*60 - per√≠odo amostral em segundos\n",
    "sample_freq = 1/period\n",
    "Nyquist = sample_freq/2\n",
    "\n",
    "\n",
    "# Read SST anomalies Dataset.\n",
    "for ds,st,d in zip(ds_list,ds_strings,depths):\n",
    "    sst = ds\n",
    "\n",
    "    # Create an EOF solver to do the EOF analysis. Square-root of cosine of\n",
    "    # latitude weights are applied before the computation of EOFs.\n",
    "    coslat = np.cos(np.deg2rad(sst.coords['latitude'].values))\n",
    "    wgts = np.sqrt(coslat)[..., np.newaxis]\n",
    "    solver = Eof(sst, weights=wgts,center=True)\n",
    "\n",
    "    # Retrieve the leading EOF, expressed as the correlation between the leading\n",
    "    # PC time series and the input SST anomalies at each grid point, and the\n",
    "    # leading PC time series itself.\n",
    "    eof1 = solver.eofsAsCorrelation(neofs=n)\n",
    "    pc1 = solver.pcs(npcs=n, pcscaling=1)\n",
    "\n",
    "    # Retrieve the Leading EOF representation, expressed as percent\n",
    "    percent['Depth_'+str(d)] = Eof.varianceFraction(solver,neigs=n)\n",
    "\n",
    "    # Plot the leading EOF expressed as correlation in the domain.\n",
    "    for i in range(0,n,1):\n",
    "\n",
    "        # Retrieve FFT from PC time series\n",
    "        Nobs = len(pc1[:,i])\n",
    "        sig_fft = rfft(pc1[:,i].values,Nobs)\n",
    "        power = np.abs(sig_fft)**2\n",
    "        sig_fftfreqs = rfftfreq(Nobs,d=sample_freq)\n",
    "        per_fftfreqs=(1./sig_fftfreqs)/365\n",
    "\n",
    "        # FIGURE\n",
    "        fig = plt.figure(figsize=(9.4,4.2)) #figsize=(3.4,5.8)\n",
    "        gs = fig.add_gridspec(3,6)\n",
    "\n",
    "        fig.subplots_adjust(left=0.15, bottom=0.1, right=.8, top=0.95, hspace=.5, wspace=1.75)\n",
    "        fig.suptitle('Depth = '+str(d)+'m', fontsize=12, y=1.05, x=.45,horizontalalignment='center')\n",
    "        fig.patch.set_facecolor('white')\n",
    "\n",
    "        # # Plot the EOF - MAP Subplot\n",
    "        ax = fig.add_subplot(gs[:,:3], projection=proj)\n",
    "        ax.set_extent(extent)\n",
    "\n",
    "        gl = ax.gridlines(crs=proj, draw_labels=True,\n",
    "                          linewidth=.5, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.xlocator = mticker.FixedLocator(np.arange(-34,-39.5,-2))\n",
    "        gl.ylocator = mticker.FixedLocator(np.arange(-5,-14.5,-2.5)) \n",
    "        gl.xlabels_top = False\n",
    "        gl.ylabels_right = False\n",
    "        gl.xformatter = LONGITUDE_FORMATTER\n",
    "        gl.yformatter = LATITUDE_FORMATTER\n",
    "        plt.rcParams.update({'font.size': 8})\n",
    "        \n",
    "        clevs = np.linspace(-1,1,100)\n",
    "        fill = eof1[i].plot.contourf(ax=ax, levels=clevs, cmap=plt.cm.RdBu_r,\n",
    "                            add_colorbar=False, transform=ccrs.PlateCarree())\n",
    "        \n",
    "        shape_feature = ShapelyFeature(Reader(shp).geometries(),\n",
    "                                        ccrs.PlateCarree(), edgecolor='gray',linewidth=.5)\n",
    "        \n",
    "        ax.add_feature(shape_feature,facecolor='oldlace')\n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        ax_cb  = divider.new_horizontal(size=\"5%\", pad=0.075, axes_class=plt.Axes)\n",
    "        cbar_ax = fig.add_axes(ax_cb)\n",
    "        cb = plt.colorbar(fill, cax= cbar_ax, orientation='vertical',) #shrink=0.8\n",
    "        cb.set_ticks([-1,0,1])\n",
    "        cb.set_label('Corr. Coefficient', fontsize=8,labelpad=-2)\n",
    "        ax.set_title('EOF' + str(i+1) + ' - ' + str((\n",
    "            percent['Depth_'+str(d)][i].values*100).round(2)) + '%', fontsize=9)\n",
    "        ax.tick_params(axis='both',labelsize=8)\n",
    "\n",
    "        # # Plot the leading PC time series.\n",
    "        ax2 = fig.add_subplot(gs[:2,3:])\n",
    "        pc1[:, i].plot(color='darkblue', linewidth=1)\n",
    "        ax2 = plt.gca()\n",
    "        ax2.axhline(0, color='k',alpha=0.5,linewidth=0.5)\n",
    "        ax2.grid(b=True, which='major', color='w', linewidth=0.5)\n",
    "        ax2.set_ylim(-5, 5)\n",
    "        ax2.set_yticks(np.arange(-4,5,1))\n",
    "        ax2.set_ylabel('Normalized Units',fontsize=8)\n",
    "        ax2.set_xlabel('Year',fontsize=8,loc='right',labelpad = -5)\n",
    "        ax2.set_title('PC' + str(i+1) + ' Time Series', fontsize=9)\n",
    "        ax2.autoscale(enable=True, axis='x', tight=True)\n",
    "        ax2.tick_params(axis='both',labelsize=8)\n",
    "        ax2.tick_params(axis='x',pad=-.5)\n",
    "        for label in ax2.get_xticklabels(which='major'):\n",
    "            label.set(rotation=25, ha='right', rotation_mode='anchor')\n",
    "\n",
    "        # # Plot FFT\n",
    "        ax3 = fig.add_subplot(gs[2:,3:])\n",
    "        # ax3.plot(per_fftfreqs,power,color='darkred', linewidth=1)#/(10**-6)\n",
    "        plt.stem(per_fftfreqs,power,linefmt='darkred',markerfmt=\" \",basefmt=None,use_line_collection=True)\n",
    "        ax3 = plt.gca()\n",
    "        ax3.grid(b=True, which='major', color='w', linewidth=0.5)\n",
    "        ax3.set_xlim(0,18)\n",
    "        ax3.set_ylabel('Power',fontsize=8)\n",
    "        ax3.set_xlabel('Period (years)',fontsize=8)\n",
    "        ax3.set_title('FFT' + str(i+1), fontsize=9)\n",
    "        ax3.tick_params(axis='both',labelsize=8)\n",
    "        ax3.ticklabel_format(axis='y',style='sci',useMathText=True,scilimits=(0,0))\n",
    "        annot_max(per_fftfreqs,power,ax=ax3)\n",
    "        \n",
    "        plt.savefig(\n",
    "            'D:/00_Masters/03_Figuras_Finais/Climatologia/Ocean_Temp/Figuras/EOF'+str(i+1)+'_'+str(d)+'.png',dpi=400, bbox_inches='tight'\n",
    "            )\n",
    "        plt.close()\n",
    "\n",
    "        tmp = pd.DataFrame({'Power':power[:],'Amplitude':sig_fft[:],'Cycles/day':sig_fftfreqs[:]})\n",
    "        tmp['Period [days]'] = np.round(((per_fftfreqs))/sample_freq,2)\n",
    "        tmp.sort_values(by=['Amplitude'], ascending=False).head(20).to_csv(\n",
    "            'D:/00_Masters/03_Figuras_Finais/Climatologia/Ocean_Temp/Outputs/EOF'+str(i+1)+'_'+str(d)+'.csv',sep=';', index=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
